---
description: 
globs: 
alwaysApply: true
---
# Testing Standards & Best Practices

## Testing Philosophy

### 1. Testing Strategy Requirements
**Rule**: Implement comprehensive testing strategy with proper test distribution and coverage priorities.

**Unit Test Priority**: Focus 70% of testing effort on unit tests for pure functions, composables, store actions/getters, and utility functions
**Integration Test Coverage**: Allocate 20% of testing effort to component integration, store integration, API integration, and composable integration
**E2E Test Focus**: Limit 10% of testing effort to critical user journeys, major feature integration, and cross-browser compatibility
**Coverage Balance**: Maintain proper balance between test types to ensure comprehensive coverage without over-testing

### 2. Test-Driven Development Standards
**Rule**: Follow TDD principles with proper development cycle and behavior-focused testing.

**Development Cycle**: Write tests before implementation using Red → Green → Refactor cycle
**Behavior Focus**: Focus on testing behavior rather than implementation details
**Edge Case Coverage**: Test edge cases and error conditions systematically
**Continuous Refactoring**: Refactor both code and tests to maintain quality and clarity

## Testing Framework Configuration

### 1. Vitest Configuration Standards
**Rule**: Configure Vitest with Vue support, JSDOM environment, and comprehensive coverage reporting.

**Environment Setup**: Use JSDOM environment for DOM testing with Vue plugin support
**Global Configuration**: Enable globals and configure test setup files for consistent test environment
**Coverage Requirements**: Set minimum 80% coverage thresholds for branches, functions, lines, and statements
**Coverage Reporting**: Use V8 provider with text, JSON, and HTML reporters for comprehensive coverage analysis
**File Exclusions**: Exclude node_modules, test files, type definitions, and config files from coverage
**Path Resolution**: Configure path aliases to match application structure for consistent imports

### 2. Test Setup Standards
**Rule**: Configure global test setup with Vue Test Utils, Pinia testing, and browser API mocks.

**Vue Test Utils**: Configure global plugins including testing Pinia with spy functions
**Pinia Testing**: Use createTestingPinia with vi.fn for spies and stubActions disabled for real action testing
**Browser API Mocks**: Mock IntersectionObserver and ResizeObserver APIs for components that use them
**Global Configuration**: Set up consistent test environment that all test files can rely on
**Mock Strategy**: Provide minimal viable mocks for browser APIs while keeping business logic real

## Unit Testing Standards

### 1. Composable Testing Requirements
**Rule**: Test composables using AAA pattern (Arrange, Act, Assert) with proper setup and teardown.

**Test Structure**: Use describe blocks for composable and method grouping with beforeEach for setup
**Async Testing**: Test async operations with proper await and promise handling
**State Validation**: Verify reactive state changes during operations (loading, completed, error states)
**Error Handling**: Test error scenarios with invalid inputs and expected error messages
**Return Value Testing**: Validate return types, method properties, and confidence ranges
**Reset Functionality**: Test state reset methods to ensure clean state between operations

### 2. Store Testing Standards
**Rule**: Test Pinia stores with proper setup, action testing, and getter validation. For comprehensive store architecture and testing patterns, refer to `pinia-stores.mdc`.

**Store Setup**: Use setActivePinia and createPinia for each test to ensure clean state
**Action Testing**: Test store actions with proper input/output validation and state changes
**Getter Testing**: Verify computed getters return correct values based on store state
**State Mutations**: Test that actions properly update store state with expected values
**Error Handling**: Test store error states and recovery mechanisms
**Async Actions**: Test async store actions with proper promise handling and loading states
**Advanced Patterns**: See pinia-stores.mdc for testing composition patterns, cross-store communication, and performance optimization

### 3. Component Testing Standards
**Rule**: Test Vue components with proper mounting, event handling, and state validation. For headless component testing patterns, refer to `vue-components.mdc`.

**Component Mounting**: Use mount with proper props and global plugin configuration
**Rendering Tests**: Verify component renders correctly with expected elements and content
**Event Testing**: Test component events are emitted with correct payloads
**State Testing**: Verify component reacts properly to prop changes and internal state updates
**Error Handling**: Test component error states and recovery mechanisms
**User Interaction**: Test user interactions like clicks, form submissions, and keyboard events
**Headless Architecture Testing**: See vue-components.mdc for comprehensive testing patterns for headless primitives and styled wrappers

## Integration Testing Standards

### 1. Component Integration Requirements
**Rule**: Test component integration with stores and other components to ensure proper data flow.

**Store Integration**: Test components with real store instances to verify state synchronization
**Event Flow**: Test event propagation between parent and child components
**Data Binding**: Verify two-way data binding works correctly with v-model and props
**Lifecycle Integration**: Test component lifecycle interactions with external services
**Real-time Updates**: Test components respond correctly to real-time data changes

### 2. API Integration Testing Standards
**Rule**: Test API integrations with proper setup, cleanup, and real-time functionality validation.

**Service Setup**: Create service instances with proper configuration for testing
**Test Data Management**: Create and cleanup test data to avoid pollution between tests
**CRUD Operations**: Test create, read, update, delete operations with proper validation
**Real-time Testing**: Test real-time subscriptions and event handling
**Error Scenarios**: Test API error handling and network failure scenarios
**Cleanup Strategy**: Ensure all test data is properly cleaned up after each test

## E2E Testing Standards

### 1. Playwright Configuration Requirements
**Rule**: Configure Playwright for comprehensive E2E testing across multiple browsers with proper CI/CD integration.

**Test Directory**: Organize E2E tests in dedicated directory with proper structure
**Browser Coverage**: Test across Chromium, Firefox, and WebKit for cross-browser compatibility
**CI Configuration**: Configure retries, workers, and reporting for CI/CD environments
**Development Server**: Automatically start development server for testing
**Trace and Screenshots**: Enable debugging tools for test failures
**Base URL Configuration**: Set consistent base URL for all tests

### 2. E2E Test Implementation Standards
**Rule**: Test complete user workflows from start to finish with proper setup and error handling.

**Workflow Testing**: Test complete user journeys including navigation, form submission, and result validation
**Error Scenario Testing**: Test error handling with network failures and invalid inputs
**Page Setup**: Use beforeEach hooks to ensure consistent starting state for each test
**Element Interaction**: Use data-testid attributes for reliable element selection
**Assertion Strategy**: Verify both successful outcomes and error states with appropriate expectations
**Network Mocking**: Mock API calls to test error scenarios and edge cases

## Test Utilities Standards

### 1. Test Factory Requirements
**Rule**: Create factory functions for generating test data with sensible defaults and override capabilities.

**Factory Pattern**: Use factory functions that accept partial overrides for flexible test data creation
**Default Values**: Provide sensible defaults for all required fields to minimize test setup
**Type Safety**: Use TypeScript generics and Partial types for type-safe overrides
**Domain Objects**: Create factories for all major domain objects (Card, GameSession, AnalysisResult)
**Realistic Data**: Use realistic values that match production data patterns
**Unique Identifiers**: Generate unique IDs to avoid test data conflicts

### 2. Custom Matcher Standards
**Rule**: Create domain-specific custom matchers for more expressive and reusable test assertions.

**Domain Validation**: Create matchers for domain-specific validation (valid cards, probabilities, etc.)
**Clear Error Messages**: Provide descriptive error messages that help debug test failures
**Type Safety**: Use proper TypeScript typing for matcher parameters and return values
**Reusable Logic**: Extract common validation logic into reusable matchers
**Extend Framework**: Use expect.extend to add custom matchers to the testing framework
**Consistent Naming**: Use consistent naming patterns for custom matchers (toBe*, toHave*, etc.)

## Coverage Requirements

### 1. Minimum Coverage Thresholds
**Rule**: Maintain minimum 80% coverage across all metrics with higher requirements for critical paths.

**Statement Coverage**: Minimum 80% statement coverage across all source files
**Branch Coverage**: Minimum 80% branch coverage for conditional logic
**Function Coverage**: Minimum 80% function coverage for all defined functions
**Line Coverage**: Minimum 80% line coverage for executable code

### 2. Critical Path Coverage Requirements
**Rule**: Implement higher coverage standards for critical business logic and security functions.

**Gambling Algorithms**: Minimum 95% coverage for all gambling calculation algorithms
**Financial Calculations**: Minimum 95% coverage for all financial and monetary calculations
**Security Functions**: Minimum 90% coverage for authentication and authorization logic
**Error Handling**: Minimum 85% coverage for error handling and recovery mechanisms

### 3. Coverage Exclusion Standards
**Rule**: Exclude appropriate files from coverage requirements while maintaining comprehensive testing.

**Type Definitions**: Exclude TypeScript type definition files from coverage requirements
**Configuration Files**: Exclude build and configuration files from coverage metrics
**Test Utilities**: Exclude test helper functions and utilities from coverage calculations
**Development Tools**: Exclude development-only tools and scripts from coverage
**Third-party Integrations**: Exclude mocked third-party integrations from coverage requirements

## Testing Best Practices

### 1. Test Organization Standards
**Rule**: Organize tests with clear structure, descriptive naming, and proper isolation.

**Grouping Strategy**: Group related tests with describe blocks for logical organization
**Naming Convention**: Use descriptive test names that explain expected behavior clearly
**AAA Pattern**: Follow Arrange, Act, Assert pattern for consistent test structure
**Test Isolation**: Keep tests focused and independent to prevent cascading failures

### 2. Mocking Strategy Standards
**Rule**: Implement strategic mocking that balances isolation with realistic testing.

**External Dependencies**: Mock external dependencies to ensure test isolation
**Internal Logic**: Use real implementations for internal business logic testing
**Time Dependencies**: Mock time-dependent functions for consistent test results
**Mocking Balance**: Avoid over-mocking that reduces test value and confidence

### 3. Data Management Standards
**Rule**: Implement systematic test data management with factories and cleanup procedures.

**Factory Usage**: Use factories for test data creation to ensure consistency
**Data Cleanup**: Clean up test data after each test to prevent pollution
**Realistic Data**: Use realistic test data that matches production patterns
**Value Variation**: Avoid hardcoded values that reduce test coverage

### 4. Async Testing Standards
**Rule**: Handle async operations properly with appropriate timeout and error handling.

**Await Operations**: Always await async operations to ensure proper test execution
**Timeout Handling**: Use proper timeout handling for async operations
**Success and Failure**: Test both success and failure cases for async operations
**Race Conditions**: Handle race conditions and timing issues in async tests

### 5. Performance Testing Standards
**Rule**: Include performance considerations in testing strategy with realistic data volumes.

**Data Volume Testing**: Test with realistic data volumes to identify performance issues
**Execution Monitoring**: Monitor test execution time to identify slow tests
**Performance Budgets**: Use performance budgets for critical operations
**Profiling**: Profile critical paths to identify optimization opportunities

This comprehensive testing framework ensures high-quality, maintainable code with proper coverage and confidence in system behavior across all testing levels.
